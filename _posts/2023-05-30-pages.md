---
layout: post
title: Dasom Ahn (Tommy Ahn) 
---

<p style='margin: 0.3in;'>
 I am a master's student in the Department of Computer Science and Engineering at Keimyung University.
 I am interested in computer vision and deep learning and doing research. 
</p>
 My current research is focused on:
   * Computation-efficient architectures that enable efficient and generic modeling for activity recognition


### Education
 - M.S., School of Computer Engineering, Keimyung University (2021.09 ~ ) - Advisor: Prof. Byoung Chul Ko
 - B.S., School of Computer Engineering, Keimyung University (2013.03 ~ 2018.02)


### Research Interest
 - Deep Learning, Computer Vision
 - Transformer
 - Facial emotion recognition, Image recognition
 - Video understanding (Action recognition, Temporal action detection, etc.)
 - Multi-modal learning


### News

* [2023/01] <a href='https://arxiv.org/abs/2210.07503'>STAR-Transformer</a> is accepted to <a href='https://wacv2023.thecvf.com/'>WACV 2023</a>.
* [2022/07] <a href='https://ieeexplore.ieee.org/document/9895100'>Shift-ViT</a> is accepted to <a href='https://www.itc-cscc2022.org/'>ITC-CSCC 2022</a>.


### Publications
(* indicates equal contribution)

####  * Conference
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size:12pt;">
 <tbody>
    <tr>
      <td style="padding:20px;width:30%;max-width:30%" align="center">
        <img style="width:100%;max-width:100%" src="../img/star.png" alt="dise">
      </td>
      <td width="75%" valign="center">
        <papertitle>STAR-Transformer: A Spatio-temporal Cross Attention Transformer for Human Action Recognition
        <br>
        <strong>Dasom Ahn</strong>, 
        <a href="https://jumpsnack.github.io/"> Sangwon Kim</a>, Hyunsu Hong, Byoung Chul Ko
        <br>
        <em>Conference on IEEE/CVF Winter Conference on Applications of Computer Vision (<strong>WACV</strong>)</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2210.07503">[arXiv]</a><a href="[https://arxiv.org/abs/2210.07503](https://openaccess.thecvf.com/content/WACV2023/papers/Ahn_STAR-Transformer_A_Spatio-Temporal_Cross_Attention_Transformer_for_Human_Action_Recognition_WACV_2023_paper.pdf)">[CVF]</a>
        <br>
        <!-- <p style="font-size:9pt;"> In action recognition, although the combination of spatio-temporal videos and skeleton features can improve the recognition performance, a separate model and balancing feature representation for cross-modal data are required. To solve these problems, we propose Spatio-TemporAl cRoss (STAR)-transformer, which can effectively represent two cross-modal features as a recognizable vector.</p> -->
    
      
    <tr>
      <td style="padding:20px;width:30%;max-width:30%" align="center">
        <img style="width:100%;max-width:100%" src="../img/shift.png" alt="dise">
      </td>
      <td width="75%" valign="center">
        <papertitle>Shift-ViT: Siamese Vision Transformer using Shifted Branches
        <br>
        <strong>Dasom Ahn</strong>, 
        Hyeongjin Kim, <a href="https://jumpsnack.github.io/"> Sangwon Kim</a>, Hyunsu Hong, Byoung Chul Ko
        <br>
        <em>International Technical Conference o Circuits/Systems, Computers and Communications (<strong>ITC-CSCC</strong>)</em>, 2022
        <br>
        <a href="https://ieeexplore.ieee.org/document/9895100">[IEEE Xplore]</a>
        <br>
      </td>
        <!-- <p style="font-size:9pt;"> In this paper, we propose a novel classification method to overcome the limitation of Vision Transformer (ViT).  ViT has no inductive bias fundamentally unlike conventional Convolution Neural Network (CNN) models. For that reason, previous ViTs are limited to handle sensitively to small changes in the image. Therefore, in this paper, we propose Shift-ViT, a new algorithm that adaptively learns image changes by extending the conventional ViT. </p> -->
    </tr>                      
    
        
####  * Domestic Papers
 - 안다솜, 김상원, 고병철, "Vision Transformer기반의 동적 얼굴 표정 인식 시스템", 2021 한국소프트웨어종합학술대회 (KSC2021), Dec. 2021      
 - 안다솜, 김상원, 고병철, "교차 주의집중 트랜스포머를 이용한 인간 행동 인식 시스템", 2022 대한전자공학회 하계종합학술대회 (Best Paper Award), pp. 839-840, Jun. 2022
         
         
### Patents
         

### Honor & Awards
 - 2022 Best Paper: IEIE, S.Korea
 - 2016 Best Paper: WISET, S.Korea
     
  

